# Machine-Learning-Algorithms-from-Scratch
## Perceptron Learning Algorithm
On the linear separable dataset the perceptron algorithm runs smoothly by producing the accuracy of 100%. After 10 fold validation the accuracy came to be 72% with the difference between the original accuracy and after validation to be 28%. The parameters used in this algorithm are the weights which are updated at each iteration when the output vector is not equal to the target or label vector and along with that the learning rate, which is in this case is kept to be 0.01. While in the breast cancer dataset the algorithm runs perfectly with the accuracy of 80%. While after validation of 10 folds the accuracy came to be 69% with the difference of 11% between the original accuracy and the accuracy after 10 fold validation. 
The termination of the linear separable dataset is normal because the perceptron algorithms work fine only when the data is linearly separable. By the name linear separable means- it can be classified linearly. This is because perceptron is a linear classifier i.e it will never get to the state with all the input vectors classified correctly if the training set D is not linearly separable, i.e. if the positive examples cannot be separated from the negative examples by a hyperplane. If the training set is linearly separable, then the perceptron is guaranteed to converge. 
While the breast cancer dataset was non-linear. Thatâ€™s why it never converges. For it to converge we stop it after some iterations and that depends on the size of the dataset. In our dataset we have 5 feature vectors and for such complex data with more than 2 features it is impossible for perceptron to classify the features into 2 linear halfspaces which is the main goal of a perceptron. And because of that it never converges and hence we get errors. After ERM on this data we get the accuracy of 80%. And after 10 fold cross validation we get 69%, i.e 31% error. This error occurs only because the perceptron cannot find a way to classify all the features into binary categories and hence never converges. This does not happen with the linearly separable dataset because in that we have only 2 feature vectors and hence the perceptron can easily classify the features into its respective classes as the work of a classifier. 
